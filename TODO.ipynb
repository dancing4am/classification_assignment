{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09d84dd3-718d-4b06-8788-172abbd182cf",
   "metadata": {},
   "source": [
    "**Extracting word features and show Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data (15 pts)**\n",
    "\n",
    "Show a few visualizations like histograms. Describe any data cleaning procedures. Based on your EDA, what is your plan of analysis? \n",
    "\n",
    "Please feel free to look at online resources on processing raw texts to feature vectors. Many methods process texts to matrix form (word embedding), including TF-IDF, GloVe, Word2Vec, etc. Pick a method and process the raw texts to word embedding. Briefly explain the method(s) and how they work in your own words. Also, do exploratory data analysis such as word statistics and/or visualization.\n",
    "\n",
    "As we did not learn natural language processing (NLP) specific techniques such as word embeddings in the lectures, we recommend reading discussions and example codes from others in the Kaggle and/or doing some research online to make sure you understand. You can refer to any resource as needed, but make sure you “demonstrate” your understanding- please include explaining in your own words, discussions, and your interpretation. Also importantly, please have a reference list at the end of the report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653fcca-ab4e-499a-9af5-eda9ea5ffe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6787e3dc-a0f0-48f5-b34b-46aa3fed7ed2",
   "metadata": {},
   "source": [
    "**Building and training models. [35 pts]**\n",
    "\n",
    "\n",
    "In the Kaggle competition, the training data has labels (category). Thus, it can be solved using supervised learning. In general, the more labeled data we have, the more accurate the supervised learning model will be. But unsupervised learning can be powerful even when there is a small number of labels or no labels. This assignment will apply an unsupervised approach, especially the matrix factorization method, to discover topics in the news articles and use the labels to check the accuracy.\n",
    "\n",
    "Here are some steps to guide this section: \n",
    "1) Think about this and answer: when you train the unsupervised model for matrix factorization, should you include texts (word features) from the test dataset or not as the input matrix? Why or why not?\n",
    "2) Build a model using the matrix factorization method(s) and predict the train and test data labels. Choose any hyperparameter (e.g., number of word features) to begin with.\n",
    "3) Measure the performances on predictions from both train and test datasets. You can use accuracy, confusion matrix, etc., to inspect the performance. You can get accuracy for the test data by submitting the result to Kaggle. \n",
    "4) Change hyperparameter(s) and record the results. We recommend including a summary table and/or graphs.\n",
    "5) Improve the model performance if you can- some ideas may include but are not limited to; using different feature extraction methods, fit models in different subsets of data, ensemble the model prediction results, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b425ae-e11e-40b8-863d-3bfa21f52246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04659f8a-f63e-4629-879c-bdae905f5d53",
   "metadata": {},
   "source": [
    "**Compare with supervised learning [30 pts]**\n",
    "\n",
    "Use the following steps to guide your work:\n",
    "\n",
    "1) Pick and train a supervised learning method(s) and compare the results (train and test performance)\n",
    "2) Discuss comparison with the unsupervised approach. You may try changing the train data size (e.g., Include only 10%, 20%, 50% of labels, and observe train/test performance changes). Which methods are data-efficient (require a smaller amount of data to achieve similar results)? What about overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43567605-c098-484c-9a9a-208abe9e78c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2314da4f-c817-4505-b0a0-0f0c3768d523",
   "metadata": {},
   "source": [
    "**Produce Deliverable: High-Quality, Organized Jupyter Notebook Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c4c92-2e1c-4035-adbb-e8bc1fe4dd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c16acc5c-4e80-4c56-ad76-5f8ba5ee3598",
   "metadata": {},
   "source": [
    "**Limitation(s) of sklearn’s non-negative matrix factorization library. [20 pts]**\n",
    "\n",
    "1. Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE. You should use sklearn library. [10 pts]\n",
    "\n",
    "\n",
    "2. Discuss the results and why sklearn's non-negative matrix facorization library did not work well compared to simple baseline or similarity-based methods we’ve done in Module 3. Can you suggest a way(s) to fix it? [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee7d9c-89c4-406f-958d-82a3bc4d122a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
